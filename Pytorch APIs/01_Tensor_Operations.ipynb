{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## torch.gather\n",
    "Gathers values along an axis specified by dim.\n",
    "沿着某一维度取特定的值\n",
    "input 和 index 维度要相同"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "t = torch.arange(9, dtype=torch.float32).reshape((3,3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 2.],\n        [3., 4., 5.],\n        [6., 7., 8.]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**out[i][j][k] = input[index[i][j][k]][j][k]**  # if dim == 0 2d\n",
    "**out[i][j] = input[index[i][j]][j]**  # if dim == 0 3d"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "gather_t_dim_0 = torch.gather(t, dim=0, index=torch.tensor([[1,2],[2,1],[0,1]])) # -> dim=0表示按行取, index[0][0]=1,index[0][1]=2\n",
    "gather_t_dim_1 = torch.gather(t, dim=1, index=torch.tensor([[1,2],[2,1],[0,1]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather_t_dim_0: tensor([[3., 7.],\n",
      "        [6., 4.],\n",
      "        [0., 4.]])\n",
      "gather_t_dim_1: tensor([[1., 2.],\n",
      "        [5., 4.],\n",
      "        [6., 7.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"gather_t_dim_0:\",gather_t_dim_0)\n",
    "print(\"gather_t_dim_1:\",gather_t_dim_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Torch.scatter\n",
    "\n",
    "Writes all values from the tensor into at the indices specified in the tensor. For each value in , its output index is specified by its index in for and by the corresponding value in for .srcselfindexsrcsrcdimension != dimindexdimension = dim\n",
    "\n",
    "用法与 ***torch.gather*** 类似, 多了一个 ***src*** , 会把 ***src*** 里的元素放到 ***input*** 里\n",
    "\n",
    "**self[index[i][j][k]][j][k] = src[i][j][k]**  # if dim == 0\n",
    "**self[index[i][j]][j] = src[i][j]**  # if dim == 0  2 dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 2.],\n        [3., 4., 5.],\n        [6., 7., 8.]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# dim=0表示按行取, index[0][0]=1,index[0][1]=2\n",
    "scatter_t_dim_0 = torch.scatter(input=torch.zeros((3,5)), dim=0, src=t,index=torch.tensor([[1,2,1],[0,2,1],[0,1,2]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6., 0., 0., 0., 0.],\n        [0., 7., 5., 0., 0.],\n        [0., 4., 8., 0., 0.]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_t_dim_0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.split\n",
    "\n",
    "split_size_or_sections: 可以是一个列表，如果是列表的话就按照列表里的数来依次划分"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 2.],\n        [3., 4., 5.],\n        [6., 7., 8.]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0., 1., 2.]]),\n tensor([[3., 4., 5.],\n         [6., 7., 8.]]))"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.split(split_size=[1,2], dim=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.stack  VS  torch.cat\n",
    "\n",
    "#### torch.stack\n",
    "- input为sequence of tensor(可以是list of tensor) **要求所有的张量维度必须一样！！**\n",
    "- stack会在指定的dim新增一个维度，如果指定dim=0，那么则在第0维新增\n",
    "\n",
    "#### torch.cat\n",
    "- cat相比stack不会新增维度，而是会在指定的dim拼接，如果指定dim=0，那么则在第0维拼接"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "t2 = torch.arange(1,10, dtype=torch.float32).reshape([3,3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.shape)\n",
    "print(t2.shape)\n",
    "print(t)\n",
    "print(t2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "t_stack_dim_0 = torch.stack([t,t2],dim=0)\n",
    "t_stack_dim_1 = torch.stack([t,t2],dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "torch.Size([3, 2, 3])\n",
      "tensor([[[0., 1., 2.],\n",
      "         [3., 4., 5.],\n",
      "         [6., 7., 8.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.],\n",
      "         [7., 8., 9.]]])\n",
      "tensor([[[0., 1., 2.],\n",
      "         [1., 2., 3.]],\n",
      "\n",
      "        [[3., 4., 5.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[6., 7., 8.],\n",
      "         [7., 8., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "print(t_stack_dim_0.shape)\n",
    "print(t_stack_dim_1.shape)\n",
    "print(t_stack_dim_0)\n",
    "print(t_stack_dim_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "t_cat_dim_0 = torch.cat([t,t2],dim=0)\n",
    "t_cat_dim_1 = torch.cat([t,t2],dim=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "torch.Size([3, 6])\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.],\n",
      "        [1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[0., 1., 2., 1., 2., 3.],\n",
      "        [3., 4., 5., 4., 5., 6.],\n",
      "        [6., 7., 8., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(t_cat_dim_0.shape)\n",
    "print(t_cat_dim_1.shape)\n",
    "print(t_cat_dim_0)\n",
    "print(t_cat_dim_1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "t = torch.randn(3,2,5,7)\n",
    "t1 = torch.randn(3,2,7,5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "t2 = torch.matmul(t, t1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 2, 5, 5])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "self must be a matrix",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-e44715d9b1c0>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mt3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmm\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mt1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m: self must be a matrix"
     ]
    }
   ],
   "source": [
    "t3 = torch.mm(t,t1)\n",
    "from timm.models import VisionTransformer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}