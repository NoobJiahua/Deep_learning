{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## torch.gather\n",
    "Gathers values along an axis specified by dim.\n",
    "沿着某一维度取特定的值\n",
    "input 和 index 维度要相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "'./outputs/ent_model.pth'"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'./outputs/ent_model.pth'.format(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = torch.arange(9, dtype=torch.float32).reshape((3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 2.],\n        [3., 4., 5.],\n        [6., 7., 8.]])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**out[i][j][k] = input[index[i][j][k]][j][k]**  # if dim == 0 2d\n",
    "**out[i][j] = input[index[i][j]][j]**  # if dim == 0 3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gather_t_dim_0 = torch.gather(t, dim=0, index=torch.tensor(\n",
    "    [[1, 2], [2, 1], [0, 1]]))  # -> dim=0表示按行取, index[0][0]=1,index[0][1]=2\n",
    "gather_t_dim_1 = torch.gather(t, dim=1, index=torch.tensor([[1, 2], [2, 1], [0, 1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gather_t_dim_0: tensor([[3., 7.],\n",
      "        [6., 4.],\n",
      "        [0., 4.]])\n",
      "gather_t_dim_1: tensor([[1., 2.],\n",
      "        [5., 4.],\n",
      "        [6., 7.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"gather_t_dim_0:\", gather_t_dim_0)\n",
    "print(\"gather_t_dim_1:\", gather_t_dim_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Torch.scatter\n",
    "\n",
    "Writes all values from the tensor into at the indices specified in the tensor. For each value in , its output index is specified by its index in for and by the corresponding value in for .srcselfindexsrcsrcdimension != dimindexdimension = dim\n",
    "\n",
    "用法与 ***torch.gather*** 类似, 多了一个 ***src*** , 会把 ***src*** 里的元素放到 ***input*** 里\n",
    "\n",
    "**self[index[i][j][k]][j][k] = src[i][j][k]**  # if dim == 0\n",
    "**self[index[i][j]][j] = src[i][j]**  # if dim == 0  2 dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 2.],\n        [3., 4., 5.],\n        [6., 7., 8.]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dim=0表示按行取, index[0][0]=1,index[0][1]=2\n",
    "scatter_t_dim_0 = torch.scatter(input=torch.zeros((3, 5)), dim=0, src=t,\n",
    "                                index=torch.tensor([[1, 2, 1], [0, 2, 1], [0, 1, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[6., 0., 0., 0., 0.],\n        [0., 7., 5., 0., 0.],\n        [0., 4., 8., 0., 0.]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scatter_t_dim_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## torch.split\n",
    "\n",
    "split_size_or_sections: 可以是一个列表，如果是列表的话就按照列表里的数来依次划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 2.],\n        [3., 4., 5.],\n        [6., 7., 8.]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[0., 1., 2.]]),\n tensor([[3., 4., 5.],\n         [6., 7., 8.]]))"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.split(split_size=[1, 2], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.rand((1, 150, 64))\n",
    "b = torch.rand((1, 150, 64))\n",
    "c = torch.arange(4).reshape((1, 1, 1, 4))\n",
    "d = torch.arange(27).reshape((3, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0,  1,  2],\n         [ 0,  0,  5],\n         [ 0,  0,  0]],\n\n        [[ 0, 10, 11],\n         [ 0,  0, 14],\n         [ 0,  0,  0]],\n\n        [[ 0, 19, 20],\n         [ 0,  0, 23],\n         [ 0,  0,  0]]])"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.triu(d, diagonal=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0, 0],\n        [2, 2],\n        [3, 3]])"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nonzero(torch.Tensor([[0.6, 0.0, 0.0, 0.0],\n",
    "                            [0.0, 0.0, 0.0, 0.0],\n",
    "                            [0.0, 0.0, 1.2, 0.0],\n",
    "                            [0.0, 0.0, 0.0, -0.4]]))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 150])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 0,  0,  0,  0,  0],\n         [ 0,  1,  2,  3,  4],\n         [ 0,  2,  4,  6,  8],\n         [ 0,  3,  6,  9, 12]],\n\n        [[ 0,  4,  8, 12, 16],\n         [ 0,  5, 10, 15, 20],\n         [ 0,  6, 12, 18, 24],\n         [ 0,  7, 14, 21, 28]],\n\n        [[ 0,  8, 16, 24, 32],\n         [ 0,  9, 18, 27, 36],\n         [ 0, 10, 20, 30, 40],\n         [ 0, 11, 22, 33, 44]]])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.einsum('bn,d -> bnd', c, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## torch.stack  VS  torch.cat\n",
    "\n",
    "#### torch.stack\n",
    "- input为sequence of tensor(可以是list of tensor) **要求所有的张量维度必须一样！！**\n",
    "- stack会在指定的dim新增一个维度，如果指定dim=0，那么则在第0维新增\n",
    "\n",
    "#### torch.cat\n",
    "- cat相比stack不会新增维度，而是会在指定的dim拼接，如果指定dim=0，那么则在第0维拼接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2 = torch.arange(1, 10, dtype=torch.float32).reshape([3, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "torch.Size([3, 3])\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(t.shape)\n",
    "print(t2.shape)\n",
    "print(t)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_stack_dim_0 = torch.stack([t, t2], dim=0)\n",
    "t_stack_dim_1 = torch.stack([t, t2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n",
      "torch.Size([3, 2, 3])\n",
      "tensor([[[0., 1., 2.],\n",
      "         [3., 4., 5.],\n",
      "         [6., 7., 8.]],\n",
      "\n",
      "        [[1., 2., 3.],\n",
      "         [4., 5., 6.],\n",
      "         [7., 8., 9.]]])\n",
      "tensor([[[0., 1., 2.],\n",
      "         [1., 2., 3.]],\n",
      "\n",
      "        [[3., 4., 5.],\n",
      "         [4., 5., 6.]],\n",
      "\n",
      "        [[6., 7., 8.],\n",
      "         [7., 8., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "print(t_stack_dim_0.shape)\n",
    "print(t_stack_dim_1.shape)\n",
    "print(t_stack_dim_0)\n",
    "print(t_stack_dim_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_cat_dim_0 = torch.cat([t, t2], dim=0)\n",
    "t_cat_dim_1 = torch.cat([t, t2], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "torch.Size([3, 6])\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.],\n",
      "        [1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[0., 1., 2., 1., 2., 3.],\n",
      "        [3., 4., 5., 4., 5., 6.],\n",
      "        [6., 7., 8., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "print(t_cat_dim_0.shape)\n",
    "print(t_cat_dim_1.shape)\n",
    "print(t_cat_dim_0)\n",
    "print(t_cat_dim_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t = torch.randn(3, 2, 5, 7)\n",
    "t1 = torch.randn(3, 2, 7, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t2 = torch.matmul(t, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 5, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2, 3, 6)\n",
    "b = torch.rand(3, 4, 3)\n",
    "c = torch.einsum(\"iko,kjk->ijo\", [a, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(12, dtype=torch.float32).reshape((3, 4))\n",
    "t1 = torch.arange(5, dtype=torch.float32)\n",
    "a = torch.einsum('bd,k->bdk', [t, t1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = t.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = t1.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.matmul(t, t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "0142bf27c0efa56b25d1671d2f1ccfb6c6dac941504631b809883bd05feaac8d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
